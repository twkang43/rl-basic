{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHEaJ2qNeOWa"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "lr            = 5e-4\n",
        "gamma         = 0.98\n",
        "buffer_limit  = 50000\n",
        "batch_size    = 32"
      ],
      "metadata": {
        "id": "ooKw4o3Bec5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer():\n",
        "  def __init__(self):\n",
        "    self.buffer = deque(maxlen=buffer_limit)\n",
        "\n",
        "  def put(self, transition):\n",
        "    self.buffer.append(transition)\n",
        "\n",
        "  def sample(self, n):\n",
        "    mini_batch = random.sample(self.buffer, n)\n",
        "    s_list, a_list, r_list, s_prime_list, done_mask_list = [], [], [], [], []\n",
        "\n",
        "    for transition in mini_batch:\n",
        "      s,a,r,s_prime,done_mask = transition\n",
        "\n",
        "      s_list.append(s)\n",
        "      a_list.append([a])\n",
        "      r_list.append([r])\n",
        "      s_prime_list.append(s_prime)\n",
        "      done_mask_list.append([done_mask])\n",
        "\n",
        "    return torch.tensor(s_list, dtype=torch.float, device=DEVICE),\\\n",
        "           torch.tensor(a_list, device=DEVICE), torch.tensor(r_list, device=DEVICE),\\\n",
        "           torch.tensor(s_prime_list, dtype=torch.float, device=DEVICE),\\\n",
        "           torch.tensor(done_mask_list, device=DEVICE)\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.buffer)"
      ],
      "metadata": {
        "id": "6mpNvnuGfjE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Qnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Qnet, self).__init__()\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(4,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.fc(x)\n",
        "\n",
        "  def sample_action(self, obs, epsilon):\n",
        "    out = self.forward(obs)\n",
        "    coin = random.random()\n",
        "    if coin < epsilon:\n",
        "      return random.randint(0,1)\n",
        "    else:\n",
        "      return out.argmax().item()"
      ],
      "metadata": {
        "id": "aSOmyALrgmPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(q, q_target, memory, optimizer):\n",
        "  for i in range(10):\n",
        "    s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "    q_out = q(s)\n",
        "    q_a = q_out.gather(1,a)\n",
        "    max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "    target = r + gamma*max_q_prime*done_mask\n",
        "    loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "6mKxHzrlhGsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  env = gym.make('CartPole-v1')\n",
        "  q = Qnet().to(DEVICE)\n",
        "  q_target = Qnet().to(DEVICE)\n",
        "  q_target.load_state_dict(q.state_dict())\n",
        "  memory = ReplayBuffer()\n",
        "\n",
        "  print_interval = 10\n",
        "  score = 0.0\n",
        "  optimizer = optim.Adam(q.parameters(), lr)\n",
        "\n",
        "  for n_epi in range(1000):\n",
        "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200))\n",
        "    s = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "      a = q.sample_action(torch.from_numpy(s).float().to(DEVICE), epsilon)\n",
        "      s_prime,r,done,_ = env.step(a)\n",
        "      done_mask = 0.0 if done else 1.0\n",
        "      memory.put((s,a,r/100.0,s_prime,done_mask))\n",
        "      s = s_prime\n",
        "\n",
        "      score += r\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    if 2000 < memory.size():\n",
        "      train(q,q_target,memory,optimizer)\n",
        "\n",
        "    if (n_epi%print_interval == 0) and (n_epi != 0):\n",
        "      q_target.load_state_dict(q.state_dict())\n",
        "      print(f\"n_epi: {n_epi}, score: {score/print_interval:.1f}, n_buffer: {memory.size()}, eps: {epsilon*100:.1f}%\")\n",
        "      score = 0.0\n",
        "\n",
        "    env.close()"
      ],
      "metadata": {
        "id": "V7sZeD-phxhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "gHeiAuoxjlQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}